Immediate todos
---------------
* NULL MOVE HEURISTIC
** It's not very effective, is it? But try it in more complex positions to be sure.
** Do we turn off writing to transposition table inside null branches or not?
** Maybe allow recursive null moves (but don't search null move if parent was a null move)

* Check divergence between non-bitboard AI and bitboard AI. The different move ordering may be responsible for the different moves, but the score for the different moves have to be the same, or else there's a bug.

* Why does Negamax BB search 2.6 million nodes on first move but vanilla only 698k? Is this entirely due to alpha-beta?
** 5-ply search with zobrist off yields different number of nodes searched.  8,835,829 vanilla, 8,832,543 BB
*** After changing move order, I get 8,835,853 for both.
** 4-ply yields 292,010 vanilla, 291,936 BB
*** After changing move order, 292,019 for both.
** NOT A BUG. It's because when it finds a move with a response that wins the game, there is a beta cutoff. This happens even with alpha-beta "disabled" because the disabling sets beta to INFINITY, and the INFINITY >= INFINITY. Thus, the number of nodes searched becomes sensitive to move order.

* Scores don't match for opening moves between non-BB Negamax and non-BB MTD(f). The score at the first divergence is 4 for Negamax and 3 for MTD(f).
** The scores for the divergence do match with Zobrist off.

* Test how long it takes for a program to create a vector and add (say) 25 elements to it 1 million times. Then you have an idea of how much your performance gain is from bitboards and how much is from avoiding 'new'.

* Make non-BB and BB versions use exactly the same search algorithm. Then you can see what value the bitboards alone bring, and you can compare the accuracy much more, well, accurately. Current known differences:
** Different move order
*** Vanilla searches clones, then jumps; BB searches square by square
*** BB searches jumps clockwise from top-left; vanilla uses a more ad-hoc order
** Performance difference: vanilla creates a vector on every move; BB does not.


Terminology
-----------
Capture square: A square the opponent can land on to capture a piece.


AI
--
Getting cute with MTD(f): check how many pieces could be captured, on average, in the leaf nodes of the tree.

Hypothesis: even-numbered plies work best, because it doesn't matter if you grab a lot of pieces only to lose a large number of them one ply later.

Bitboards are MUCH faster per node than vanilla in debug build. This may be a good incentive for keeping them.

Iterative deepening should cut off search once a score of +inf has been found. No need to search to 4 ply if the game will end in 3 moves.

What happens if a score of -inf is detected? Will the computer start making random moves, since no move seems better than any other? And (once we allow them) what about draws?
* A solution here is to give the highest score to the move that defers loss the longest. Alternatively, it could return the result of the shallowest search that doesn't return a score of -inf (iterative shallowing?).

Can get some randomness by sorting moves in a random order for root node before searching them (might still search clones first, though). Iterative deepening and the way MTD(f) works in general might interfere with this, though. You wouldn't want to randomize on any search other than the first (since you want to search best first), but the game's idea of the best move might change between searches. I also wouldn't be surprised if the randomness is not as uniform as it should be.

I think this game will show significant even/odd swings, so NegaScout may be better than MTD(f)

MTD(f) is making different moves than negamax, even with zobrist hashing off. Is this normal?

Zobrist hashing can be improved by using a "hash lock" -- instead of recording the full_hash, compute and record a DIFFERENT hash. Implement by modifying calcHash to accept different tables. There is the unfortunate side effect, though, that this doubles the time spent hashing.

Empty squares do not need to be added to zobrist hash (may not hurt, though)

For performance, could turn off randomness when number of pieces on board is >=N (thus allowing more cutoffs, since we can test score >= beta rather than score > beta)

Always examine one ply deeper when there is only one legal move (repeat as necessary).

Should give higher scores to winning the game in fewer moves, so the computer always plays the quickest win, not the first it finds. (If the win is only a few ply away, though, iterative deepening will catch it at the shallowest possible depth.)

Try null move heuristic

Try killer move heuristic

Consider quiescence search: after a certain number of ply, examine only moves that capture. But unlike chess, I think a higher proportion of possible moves will be capture moves, and also unlike chess, the number of pieces does not go down with each capture.

Repetition could complicate searches (i.e. if CPU returns to a previous position during its search, but does not realize it)

I'm thinking a piece is worth 100 points, a capture square is worth -N points (to encourage the algorithm to err on the side of reducing its capture squares), where N is the number of pieces that will be captured if the opponent moves there. (Calculate by iterating through the board, and if piece is of our color, adding up all the empty squares that neighbor it)

I'm thinking of using iterative deepening for 2 or 3 ply before switching to Negascout or MTD(f). This increases the probability of having found a decent move if the search is forced to terminate early.


Time control
------------
Suppose you have 5 seconds for the next move. If after any ply more than 2.5 seconds have elapsed, you can probably terminate, since it's doubtful you will complete another ply with half your time remaining.


Testing AI
----------
Confirm findMoves and findAllPossibleMoves yield the same scores for every position

Generate (say) 1 million random positions. Verify that Negamax w/o alpha-beta, Negamax w/alpha-beta, and Negascout always return the same result for an N-ply search.

Also try random positions with different version of the algorithm to see how they perform.


Evaluating a position with bitboards
------------------------------------
Counting number of 1's one bit at a time:

    int count = 0;
    for(uint64 bits = bitboard; bits != 0; bits >>= 1) {
        count += bits & 1;
    }


Counting number of 1's with a lookup table (COUNT_BITS is 16-bit):

    int count = COUNT_BITS[bitboard & 0xffff];
    count += COUNT_BITS[(bitboard >> 16) & 0xffff];
    count += COUNT_BITS[(bitboard >> 32) & 0xffff];
    count += COUNT_BITS[(bitboard >> 48) & 0xffff];

Or equivalently:

    int count = 0;
    for(uint64 bits = bitboard; bits != 0; bits >>= 16) {
        count += COUNT_BITS[bits & 0xffff];
    }

A very similar trick can also be used with bitboards to make zobrist hashes!

    uint64 hash = ZOBRIST_BLUE1[bb_blue & 0xffff];
    hash ^= ZOBRIST_BLUE2[(bb_blue >> 16) & 0xffff];
    hash ^= ZOBRIST_BLUE3[(bb_blue >> 32) & 0xffff];
    hash ^= ZOBRIST_BLUE4[(bb_blue >> 48) & 0xffff];

Then repeat for red, and then hash in whose turn it is to move.


Draw bitboard routine
---------------------
def drawbb(bitboard):
    out = ""
    bit = 1
    for i in xrange(49):
        out += "1" if bitboard & bit else "0"
        if i % 7 == 6:
            out += "\n"
        bit <<= 1
    print out
