DEEP SPOT
=========

Immediate todos
---------------
* Improving move order by searching non-capturing jumps last has slowed down the AI's nodes/sec considerably. Need to check whether the number of branches pruned outweigh this.

* BB and vanilla move order no longer match again, since BB now searches non-capturing jumps last.

* CPU MADE ILLEGAL MOVE. Had only one move available at end of game and passed. "Searched 77 nodes in 0 seconds"
** Must not have found a better move than alpha, which was -INFINITY, and so returned no move.

* Now that WIN and LOSS are no longer infinity, you won't get a beta cutoff when a win is detected and beta is INFINITY, so you may want to change the beta cutoff check to check for WIN too.

* DID WE BREAK ALPHA-BETA AND/OR ZOBRIST??
** At 8 ply, best-first on, null move off, iterative negamax used to search 6,429,292 nodes after a1-b1. Now it searches 9,606,792 (returning the same score). However, MTD(f) searched 6,535,305 with the old method (returning a score of -4) and 1,600,989 with the new (returning a score of -1). What's going on??
*** We may have to do a 2-ply search and just brute-force it by hand to see what it SHOULD be doing versus what it IS doing.

* MTD(f) does not match between BB and non-BB w/ zobrist on -- but iterative negamax does match, and MTD(f) matches with zobrist off.
** It's because BB version looks root node up in transposition table and vanilla does not. I'm unclear on why this is causing BB to search *more* nodes.

* What happens in MTD(f) when the CPU is about to lose the game? Is it gonna slide the null window towards LOSS one at a time, since it will fail low over and over?
** May not be a problem in practice. If you're about to lose, it doesn't really matter what move you play, and you'll find at least one move if you're doing iterative deepening, so the time limit might take care of it.
*** But will the same thing happen if the CPU is about to win, sliding towards WIN? Obviously you DO want to find the right move in that case!

* NULL MOVE HEURISTIC
** Make sure null move is never recorded as best move in zobrist!
** It's not very effective, is it? But try it in more complex positions to be sure.
** Do we turn off writing to transposition table inside null branches or not?
** Maybe allow recursive null moves (but don't search null move if parent was a null move)

* Make non-BB and BB versions use exactly the same search algorithm. Then you can see what value the bitboards alone bring, and you can compare the accuracy much more, well, accurately. Current known differences:
** Performance difference: vanilla creates a vector on every move; BB does not.


Terminology
-----------
Capture square: A square the opponent can land on to capture a piece.


AI
--
In addition to searching them last, we could penalize non-capturing jumps by analyzing them to a shallower depth (decrementing depth by more than one). In fact, we could penalize *all* non-capturing moves.
* Tread carefully here. Analyzing moves to a shallower depth mean you have less of an idea of the consequences. Better check if this weakens the AI significantly.

Do we ignore the transposition table at depth 0? Doing so does result in a 2x speed boost as of this writing, but then it can't benefit from any scores recorded for the same position at a higher depth -- but is that really a benefit anyway? (I know at least some chess programs do consult the transposition table before evaluating the position.)

Consider using 256-entry zobrist LUTs instead of 64k-entry LUTs for mobile devices (may work better with cache)

Try Enhanced Transposition Cutoffs (ETC) -- basically, check if any children nodes are in the transposition table and cut off if there is a beta cutoff. This is expensive, so is only worth doing higher up in the tree.

Hypothesis: even-numbered plies work best, because it doesn't matter if you grab a lot of pieces only to lose a large number of them one ply later.

Iterative deepening should cut off search once a score of +inf has been found. No need to search to 4 ply if the game will end in 3 moves.
* Do we do the same for a score of -inf?

What happens if a score of -inf is detected? Will the computer start making random moves, since no move seems better than any other? And (once we allow them) what about draws?
* A solution here is to give the highest score to the move that defers loss the longest. Alternatively, it could return the result of the shallowest search that doesn't return a score of -inf (iterative shallowing?).

The order in which the CPU looks for jumps is still not randomized.

I think this game will show significant even/odd swings, so NegaScout may be better than MTD(f)

MTD(f) is making different moves than negamax, even with zobrist hashing off. Is this normal?

Zobrist hashing can be improved by using a "hash lock" -- instead of recording the full_hash, compute and record a DIFFERENT hash. Implement by modifying calcHash to accept different tables. There is the unfortunate side effect, though, that this doubles the time spent hashing.

Always examine one ply deeper when there is only one legal move (repeat as necessary).

Should give higher scores to winning the game in fewer moves, so the computer always plays the quickest win, not the first it finds. (If the win is only a few ply away, though, iterative deepening will catch it at the shallowest possible depth.)

Consider killer move heuristic

There might be situations analogous to superko in Go that would cause a game between two AIs to continue endlessly.


Position evaluation
-------------------
Naive evaluation method: simply subtract the number of enemy pieces from your own pieces.
* Extremely fast to calculate thanks to fast ways to count bits. As of this writing, it's a good deal faster than looking up the board in the transposition table.

Capture squares method: I'm thinking a piece is worth 100 points, a capture square is worth -N points (to encourage the algorithm to err on the side of reducing its capture squares), where N is the number of pieces that will be captured if the opponent moves there. (Calculate by iterating through the board, and if piece is of our color, adding up all the empty squares that neighbor it)

Mobility method: pieces that can't move are scored slightly less than pieces that can. This should encourage the CPU to trap its opponent's pieces. Perhaps pieces are scored 1000 each (this would require using ints instead of shorts for the score), then 1 point is added for each square it can move to.

The danger of fancier evaluation methods is they will slow down the algorithm severely, reducing the number of ply that can be searched and possibly negating the advantage.


Time control
------------
Suppose you have 5 seconds for the next move. If after any ply more than 2.5 seconds have elapsed, you can probably terminate, since it's doubtful you will complete another ply with half your time remaining.


Testing AI
----------
Confirm findMoves and findAllPossibleMoves yield the same scores for every position

Generate (say) 1 million random positions. Verify that Negamax w/o alpha-beta, Negamax w/alpha-beta, and Negascout always return the same result for an N-ply search.

Also try random positions with different version of the algorithm to see how they perform.


AI personalities
----------------
Possible differences among them:
* Evaluation function
* Order of move generation (some may have a predilection for diagonal moves, for instance)
* Number of plies and/or time to think
* Minimax-based vs. rules-based (perhaps instead of rules-based we'd use a modified 2-ply negamax that has some heuristics to guard against un-human-like moves)

Possible names:
* Tony (weakest player)
* Derpy
* Doofus
* Bessie (avatar: a cow)
* Dr. Watt
* Orion
* Sammie
* Phil Heckmuth (highly speculative playstyle)
* Dr. Robotvinnik (avatar: caricature of Mikhail Botvinnik w/ orange moustache)
* Hannibal (hyperaggressive)
* Cruise Elroy (avatar: reminiscent of red Pac-Man ghost)
* Emerson
* Dazzler
* Spotmaster 9000
* Deep Spot (avatar: HHGttG's Deep Thought w/ Cool Spot's sunglasses?)
* God (if we devise a perfect player -- unlikely!)

I'm imagining a tournament ladder where you have to beat many of these


Draw bitboard routine
---------------------
def drawbb(bitboard):
    out = ""
    bit = 1
    for i in xrange(49):
        out += "1" if bitboard & bit else "0"
        if i % 7 == 6:
            out += "\n"
        bit <<= 1
    print out
